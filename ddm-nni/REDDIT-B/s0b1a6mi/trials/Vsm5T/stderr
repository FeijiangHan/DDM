Traceback (most recent call last):
  File "main_graph.py", line 215, in <module>
    f1 = main(cfg)
  File "main_graph.py", line 163, in main
    test_f1 = graph_classification_evaluation(model, cfg.eval_T, pooler, eval_loader,
  File "/ddm-nni/REDDIT-B/evaluator.py", line 51, in graph_classification_evaluation
    out = model.embed(batch_g, feat, t)
  File "/ddm-nni/REDDIT-B/models/DDM.py", line 118, in embed
    x_t, time_embed, g  = self.sample_q(t, x, g)
  File "/ddm-nni/REDDIT-B/models/DDM.py", line 98, in sample_q
    noise = F.layer_norm(noise, (noise.shape[-1], ))
  File "/root/miniconda3/envs/nni/lib/python3.8/site-packages/torch/nn/functional.py", line 2347, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: CUDA out of memory. Tried to allocate 1.29 GiB (GPU 0; 23.70 GiB total capacity; 3.88 GiB already allocated; 687.56 MiB free; 3.89 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
