Traceback (most recent call last):
  File "main_graph.py", line 215, in <module>
    f1 = main(cfg)
  File "main_graph.py", line 163, in main
    test_f1 = graph_classification_evaluation(model, cfg.eval_T, pooler, eval_loader,
  File "/ddm-nni/REDDIT-B/evaluator.py", line 51, in graph_classification_evaluation
    out = model.embed(batch_g, feat, t)
  File "/ddm-nni/REDDIT-B/models/DDM.py", line 119, in embed
    _, hidden = self.net(g, x_t=x_t, time_embed=time_embed)
  File "/root/miniconda3/envs/nni/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/ddm-nni/REDDIT-B/models/mlp_gat.py", line 89, in forward
    out_hidden = torch.cat(out_hidden, dim=-1)
RuntimeError: CUDA out of memory. Tried to allocate 3.28 GiB (GPU 0; 23.70 GiB total capacity; 13.43 GiB already allocated; 2.00 GiB free; 19.09 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
