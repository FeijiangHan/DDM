[2023-03-21 20:05:26] PRINT ---new cfg------
[2023-03-21 20:05:26] PRINT {'DATA': {'data_name': 'photo'}, 'DATALOADER': {'NUM_WORKERS': 0}, 'MODEL': {'num_hidden': 1024, 'num_layers': 2, 'nhead': 4, 'activation': 'prelu', 'attn_drop': 0.2, 'feat_drop': 0.2, 'norm': 'batchnorm', 'pooler': 'mean', 'beta_schedule': 'sigmoid', 'beta_1': 9.923328161551092e-05, 'beta_T': 0.05757239120582874, 'T': 200}, 'SOLVER': {'optim_type': 'adam', 'optim_type_f': 'adamw', 'alpha': 1, 'decay': 30, 'LR': 0.000322265805676416, 'LR_f': 0.0005537471737832091, 'weight_decay': 0, 'weight_decay_f': 4.7493036893105135e-06, 'MAX_EPOCH': 150, 'max_epoch_f': 100}, 'DEVICE': 'cuda', 'seeds': [0], 'eval_T': [50, 100, 200], 'output_dir': '/ddm-nni/AmazonCoBuyPhotoDataset/log', 'checkpoint_dir': '/ddm-nni/AmazonCoBuyPhotoDataset/log/checkpoint'}
[2023-03-21 20:05:26] PRINT [03/21 20:05:26 graph]: Rank of current process: 0. World size: 1
[2023-03-21 20:05:29] PRINT [03/21 20:05:29 graph]: Environment info:
[2023-03-21 20:05:29] PRINT PyTorch version: 1.10.0+cu113
[2023-03-21 20:05:29] PRINT Is debug build: False
[2023-03-21 20:05:29] PRINT CUDA used to build PyTorch: 11.3
[2023-03-21 20:05:29] PRINT ROCM used to build PyTorch: N/A
[2023-03-21 20:05:29] PRINT 
[2023-03-21 20:05:29] PRINT OS: Ubuntu 20.04.3 LTS (x86_64)
[2023-03-21 20:05:29] PRINT GCC version: (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
[2023-03-21 20:05:29] PRINT Clang version: Could not collect
[2023-03-21 20:05:29] PRINT CMake version: version 3.16.3
[2023-03-21 20:05:29] PRINT Libc version: glibc-2.31
[2023-03-21 20:05:29] PRINT 
[2023-03-21 20:05:29] PRINT Python version: 3.8.10 (default, Jun  4 2021, 15:09:15)  [GCC 7.5.0] (64-bit runtime)
[2023-03-21 20:05:29] PRINT Python platform: Linux-5.4.0-90-generic-x86_64-with-glibc2.17
[2023-03-21 20:05:29] PRINT Is CUDA available: True
[2023-03-21 20:05:29] PRINT CUDA runtime version: 11.3.109
[2023-03-21 20:05:29] PRINT GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
[2023-03-21 20:05:29] PRINT Nvidia driver version: 495.44
[2023-03-21 20:05:29] PRINT cuDNN version: Probably one of the following:
[2023-03-21 20:05:29] PRINT /usr/lib/x86_64-linux-gnu/libcudnn.so.8.2.0
[2023-03-21 20:05:29] PRINT /usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.2.0
[2023-03-21 20:05:29] PRINT /usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.2.0
[2023-03-21 20:05:29] PRINT /usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.2.0
[2023-03-21 20:05:29] PRINT /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.2.0
[2023-03-21 20:05:29] PRINT /usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.2.0
[2023-03-21 20:05:29] PRINT /usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.2.0
[2023-03-21 20:05:29] PRINT HIP runtime version: N/A
[2023-03-21 20:05:29] PRINT MIOpen runtime version: N/A
[2023-03-21 20:05:29] PRINT 
[2023-03-21 20:05:29] PRINT Versions of relevant libraries:
[2023-03-21 20:05:29] PRINT [pip3] numpy==1.23.5
[2023-03-21 20:05:29] PRINT [pip3] torch==1.10.0+cu113
[2023-03-21 20:05:29] PRINT [pip3] torchvision==0.11.1+cu113
[2023-03-21 20:05:29] PRINT [conda] blas                      1.0                         mkl    https://mirrors.ustc.edu.cn/anaconda/pkgs/main
[2023-03-21 20:05:29] PRINT [conda] mkl                       2021.4.0           h06a4308_640    https://mirrors.ustc.edu.cn/anaconda/pkgs/main
[2023-03-21 20:05:29] PRINT [conda] mkl-service               2.4.0            py38h7f8727e_0    https://mirrors.ustc.edu.cn/anaconda/pkgs/main
[2023-03-21 20:05:29] PRINT [conda] mkl_fft                   1.3.1            py38hd3c417c_0    https://mirrors.ustc.edu.cn/anaconda/pkgs/main
[2023-03-21 20:05:29] PRINT [conda] mkl_random                1.2.2            py38h51133e4_0    https://mirrors.ustc.edu.cn/anaconda/pkgs/main
[2023-03-21 20:05:29] PRINT [conda] numpy                     1.21.4                   pypi_0    pypi
[2023-03-21 20:05:29] PRINT [conda] numpy-base                1.23.5           py38h31eccc5_0    https://mirrors.ustc.edu.cn/anaconda/pkgs/main
[2023-03-21 20:05:29] PRINT [conda] torch                     1.10.0+cu113             pypi_0    pypi
[2023-03-21 20:05:29] PRINT [conda] torchvision               0.11.1+cu113             pypi_0    pypi
[2023-03-21 20:05:29] PRINT         Pillow (8.4.0)
[2023-03-21 20:05:29] PRINT [03/21 20:05:29 graph]: Command line arguments: Namespace(local_rank=0, resume=False, seed=1234, start_epoch=0)
[2023-03-21 20:05:29] PRINT [03/21 20:05:29 graph]: Run 0th for seed 0
[2023-03-21 20:05:30] PRINT [03/21 20:05:30 graph]: Total trainable params num : 23067055
[2023-03-21 20:05:36] PRINT [03/21 20:05:36 graph]: ----------Start Training----------
[2023-03-21 20:05:36] PRINT [03/21 20:05:36 graph]: start epoch 0.
[2023-03-21 20:05:37] PRINT [03/21 20:05:37 graph]: # Epoch 0: train_loss: 0.9887 | lr: 0.000322
[2023-03-21 20:05:37] PRINT [03/21 20:05:37 graph]: start epoch 1.
[2023-03-21 20:05:37] PRINT [03/21 20:05:37 graph]: # Epoch 1: train_loss: 0.7531 | lr: 0.000322
[2023-03-21 20:05:37] PRINT [03/21 20:05:37 graph]: start epoch 2.
[2023-03-21 20:05:37] PRINT [03/21 20:05:37 graph]: # Epoch 2: train_loss: 0.6495 | lr: 0.000322
[2023-03-21 20:05:37] PRINT [03/21 20:05:37 graph]: start epoch 3.
[2023-03-21 20:05:37] PRINT [03/21 20:05:37 graph]: # Epoch 3: train_loss: 0.6055 | lr: 0.000322
[2023-03-21 20:05:37] PRINT [03/21 20:05:37 graph]: start epoch 4.
[2023-03-21 20:05:38] PRINT [03/21 20:05:38 graph]: # Epoch 4: train_loss: 0.5819 | lr: 0.000322
[2023-03-21 20:05:38] PRINT [03/21 20:05:38 graph]: start epoch 5.
[2023-03-21 20:05:38] PRINT [03/21 20:05:38 graph]: # Epoch 5: train_loss: 0.5674 | lr: 0.000322
[2023-03-21 20:05:38] PRINT [03/21 20:05:38 graph]: start epoch 6.
[2023-03-21 20:05:38] PRINT [03/21 20:05:38 graph]: # Epoch 6: train_loss: 0.5529 | lr: 0.000322
[2023-03-21 20:05:38] PRINT [03/21 20:05:38 graph]: start epoch 7.
[2023-03-21 20:05:38] PRINT [03/21 20:05:38 graph]: # Epoch 7: train_loss: 0.5405 | lr: 0.000322
[2023-03-21 20:05:38] PRINT [03/21 20:05:38 graph]: start epoch 8.
[2023-03-21 20:05:38] PRINT [03/21 20:05:38 graph]: # Epoch 8: train_loss: 0.5312 | lr: 0.000322
[2023-03-21 20:05:38] PRINT [03/21 20:05:38 graph]: start epoch 9.
[2023-03-21 20:05:39] PRINT [03/21 20:05:39 graph]: # Epoch 9: train_loss: 0.5232 | lr: 0.000322
[2023-03-21 20:05:39] PRINT [03/21 20:05:39 graph]: start epoch 10.
[2023-03-21 20:05:39] PRINT [03/21 20:05:39 graph]: # Epoch 10: train_loss: 0.5156 | lr: 0.000322
[2023-03-21 20:05:39] PRINT [03/21 20:05:39 graph]: start epoch 11.
[2023-03-21 20:05:39] PRINT [03/21 20:05:39 graph]: # Epoch 11: train_loss: 0.5079 | lr: 0.000322
[2023-03-21 20:05:39] PRINT [03/21 20:05:39 graph]: start epoch 12.
[2023-03-21 20:05:39] PRINT [03/21 20:05:39 graph]: # Epoch 12: train_loss: 0.5021 | lr: 0.000322
[2023-03-21 20:05:39] PRINT [03/21 20:05:39 graph]: start epoch 13.
[2023-03-21 20:05:39] PRINT [03/21 20:05:39 graph]: # Epoch 13: train_loss: 0.4967 | lr: 0.000322
[2023-03-21 20:05:39] PRINT [03/21 20:05:39 graph]: start epoch 14.
[2023-03-21 20:05:40] PRINT [03/21 20:05:40 graph]: # Epoch 14: train_loss: 0.4923 | lr: 0.000322
[2023-03-21 20:05:40] PRINT [03/21 20:05:40 graph]: start epoch 15.
[2023-03-21 20:05:40] PRINT [03/21 20:05:40 graph]: # Epoch 15: train_loss: 0.4880 | lr: 0.000322
[2023-03-21 20:05:40] PRINT [03/21 20:05:40 graph]: start epoch 16.
[2023-03-21 20:05:40] PRINT [03/21 20:05:40 graph]: # Epoch 16: train_loss: 0.4844 | lr: 0.000322
[2023-03-21 20:05:40] PRINT [03/21 20:05:40 graph]: start epoch 17.
[2023-03-21 20:05:40] PRINT [03/21 20:05:40 graph]: # Epoch 17: train_loss: 0.4803 | lr: 0.000322
[2023-03-21 20:05:40] PRINT [03/21 20:05:40 graph]: start epoch 18.
[2023-03-21 20:05:40] PRINT [03/21 20:05:40 graph]: # Epoch 18: train_loss: 0.4765 | lr: 0.000322
[2023-03-21 20:05:40] PRINT [03/21 20:05:40 graph]: start epoch 19.
[2023-03-21 20:05:41] PRINT [03/21 20:05:41 graph]: # Epoch 19: train_loss: 0.4733 | lr: 0.000322
[2023-03-21 20:05:41] PRINT [03/21 20:05:41 graph]: start epoch 20.
[2023-03-21 20:05:41] PRINT [03/21 20:05:41 graph]: # Epoch 20: train_loss: 0.4709 | lr: 0.000322
[2023-03-21 20:05:41] PRINT [03/21 20:05:41 graph]: start epoch 21.
[2023-03-21 20:05:41] PRINT [03/21 20:05:41 graph]: # Epoch 21: train_loss: 0.4697 | lr: 0.000322
[2023-03-21 20:05:41] PRINT [03/21 20:05:41 graph]: start epoch 22.
[2023-03-21 20:05:41] PRINT [03/21 20:05:41 graph]: # Epoch 22: train_loss: 0.4674 | lr: 0.000322
[2023-03-21 20:05:41] PRINT [03/21 20:05:41 graph]: start epoch 23.
[2023-03-21 20:05:41] PRINT [03/21 20:05:41 graph]: # Epoch 23: train_loss: 0.4690 | lr: 0.000322
[2023-03-21 20:05:41] PRINT [03/21 20:05:41 graph]: start epoch 24.
[2023-03-21 20:05:42] PRINT [03/21 20:05:42 graph]: # Epoch 24: train_loss: 0.4625 | lr: 0.000322
[2023-03-21 20:05:42] PRINT [03/21 20:05:42 graph]: start epoch 25.
[2023-03-21 20:05:42] PRINT [03/21 20:05:42 graph]: # Epoch 25: train_loss: 0.4706 | lr: 0.000322
[2023-03-21 20:05:42] PRINT [03/21 20:05:42 graph]: start epoch 26.
[2023-03-21 20:05:42] PRINT [03/21 20:05:42 graph]: # Epoch 26: train_loss: 0.4675 | lr: 0.000322
[2023-03-21 20:05:42] PRINT [03/21 20:05:42 graph]: start epoch 27.
[2023-03-21 20:05:42] PRINT [03/21 20:05:42 graph]: # Epoch 27: train_loss: 0.4724 | lr: 0.000322
[2023-03-21 20:05:42] PRINT [03/21 20:05:42 graph]: start epoch 28.
[2023-03-21 20:05:43] PRINT [03/21 20:05:43 graph]: # Epoch 28: train_loss: 0.4644 | lr: 0.000322
[2023-03-21 20:05:43] PRINT [03/21 20:05:43 graph]: start epoch 29.
[2023-03-21 20:05:43] PRINT [03/21 20:05:43 graph]: # Epoch 29: train_loss: 0.4570 | lr: 0.000322
[2023-03-21 20:05:43] PRINT [03/21 20:05:43 graph]: start epoch 30.
[2023-03-21 20:05:43] PRINT [03/21 20:05:43 graph]: # Epoch 30: train_loss: 0.4643 | lr: 0.000322
[2023-03-21 20:05:43] PRINT [03/21 20:05:43 graph]: start epoch 31.
[2023-03-21 20:05:43] PRINT [03/21 20:05:43 graph]: # Epoch 31: train_loss: 0.4579 | lr: 0.000322
[2023-03-21 20:05:43] PRINT [03/21 20:05:43 graph]: start epoch 32.
[2023-03-21 20:05:43] PRINT [03/21 20:05:43 graph]: # Epoch 32: train_loss: 0.4535 | lr: 0.000322
[2023-03-21 20:05:43] PRINT [03/21 20:05:43 graph]: start epoch 33.
[2023-03-21 20:05:44] PRINT [03/21 20:05:44 graph]: # Epoch 33: train_loss: 0.4553 | lr: 0.000322
[2023-03-21 20:05:44] PRINT [03/21 20:05:44 graph]: start epoch 34.
[2023-03-21 20:05:44] PRINT [03/21 20:05:44 graph]: # Epoch 34: train_loss: 0.4551 | lr: 0.000322
[2023-03-21 20:05:44] PRINT [03/21 20:05:44 graph]: start epoch 35.
[2023-03-21 20:05:44] PRINT [03/21 20:05:44 graph]: # Epoch 35: train_loss: 0.4514 | lr: 0.000322
[2023-03-21 20:05:44] PRINT [03/21 20:05:44 graph]: start epoch 36.
[2023-03-21 20:05:44] PRINT [03/21 20:05:44 graph]: # Epoch 36: train_loss: 0.4496 | lr: 0.000322
[2023-03-21 20:05:44] PRINT [03/21 20:05:44 graph]: start epoch 37.
[2023-03-21 20:05:44] PRINT [03/21 20:05:44 graph]: # Epoch 37: train_loss: 0.4503 | lr: 0.000322
[2023-03-21 20:05:44] PRINT [03/21 20:05:44 graph]: start epoch 38.
[2023-03-21 20:05:45] PRINT [03/21 20:05:45 graph]: # Epoch 38: train_loss: 0.4491 | lr: 0.000322
[2023-03-21 20:05:45] PRINT [03/21 20:05:45 graph]: start epoch 39.
[2023-03-21 20:05:45] PRINT [03/21 20:05:45 graph]: # Epoch 39: train_loss: 0.4463 | lr: 0.000322
[2023-03-21 20:05:45] PRINT [03/21 20:05:45 graph]: start epoch 40.
[2023-03-21 20:05:45] PRINT [03/21 20:05:45 graph]: # Epoch 40: train_loss: 0.4462 | lr: 0.000322
[2023-03-21 20:05:45] PRINT [03/21 20:05:45 graph]: start epoch 41.
[2023-03-21 20:05:45] PRINT [03/21 20:05:45 graph]: # Epoch 41: train_loss: 0.4462 | lr: 0.000322
[2023-03-21 20:05:45] PRINT [03/21 20:05:45 graph]: start epoch 42.
[2023-03-21 20:05:45] PRINT [03/21 20:05:45 graph]: # Epoch 42: train_loss: 0.4444 | lr: 0.000322
[2023-03-21 20:05:45] PRINT [03/21 20:05:45 graph]: start epoch 43.
[2023-03-21 20:05:46] PRINT [03/21 20:05:46 graph]: # Epoch 43: train_loss: 0.4430 | lr: 0.000322
[2023-03-21 20:05:46] PRINT [03/21 20:05:46 graph]: start epoch 44.
[2023-03-21 20:05:46] PRINT [03/21 20:05:46 graph]: # Epoch 44: train_loss: 0.4419 | lr: 0.000322
[2023-03-21 20:05:46] PRINT [03/21 20:05:46 graph]: start epoch 45.
[2023-03-21 20:05:46] PRINT [03/21 20:05:46 graph]: # Epoch 45: train_loss: 0.4417 | lr: 0.000322
[2023-03-21 20:05:46] PRINT [03/21 20:05:46 graph]: start epoch 46.
[2023-03-21 20:05:46] PRINT [03/21 20:05:46 graph]: # Epoch 46: train_loss: 0.4403 | lr: 0.000322
[2023-03-21 20:05:46] PRINT [03/21 20:05:46 graph]: start epoch 47.
[2023-03-21 20:05:46] PRINT [03/21 20:05:46 graph]: # Epoch 47: train_loss: 0.4390 | lr: 0.000322
[2023-03-21 20:05:46] PRINT [03/21 20:05:46 graph]: start epoch 48.
[2023-03-21 20:05:47] PRINT [03/21 20:05:47 graph]: # Epoch 48: train_loss: 0.4383 | lr: 0.000322
[2023-03-21 20:05:47] PRINT [03/21 20:05:47 graph]: start epoch 49.
[2023-03-21 20:05:47] PRINT [03/21 20:05:47 graph]: # Epoch 49: train_loss: 0.4373 | lr: 0.000322
[2023-03-21 20:05:47] PRINT [03/21 20:05:47 graph]: start epoch 50.
[2023-03-21 20:05:47] PRINT [03/21 20:05:47 graph]: # Epoch 50: train_loss: 0.4361 | lr: 0.000322
[2023-03-21 20:05:47] PRINT [03/21 20:05:47 graph]: start epoch 51.
[2023-03-21 20:05:47] PRINT [03/21 20:05:47 graph]: # Epoch 51: train_loss: 0.4354 | lr: 0.000322
[2023-03-21 20:05:47] PRINT [03/21 20:05:47 graph]: start epoch 52.
[2023-03-21 20:05:48] PRINT [03/21 20:05:48 graph]: # Epoch 52: train_loss: 0.4340 | lr: 0.000322
[2023-03-21 20:05:48] PRINT [03/21 20:05:48 graph]: start epoch 53.
[2023-03-21 20:05:48] PRINT [03/21 20:05:48 graph]: # Epoch 53: train_loss: 0.4333 | lr: 0.000322
[2023-03-21 20:05:48] PRINT [03/21 20:05:48 graph]: start epoch 54.
[2023-03-21 20:05:48] PRINT [03/21 20:05:48 graph]: # Epoch 54: train_loss: 0.4322 | lr: 0.000322
[2023-03-21 20:05:48] PRINT [03/21 20:05:48 graph]: start epoch 55.
[2023-03-21 20:05:48] PRINT [03/21 20:05:48 graph]: # Epoch 55: train_loss: 0.4313 | lr: 0.000322
[2023-03-21 20:05:48] PRINT [03/21 20:05:48 graph]: start epoch 56.
[2023-03-21 20:05:48] PRINT [03/21 20:05:48 graph]: # Epoch 56: train_loss: 0.4303 | lr: 0.000322
[2023-03-21 20:05:48] PRINT [03/21 20:05:48 graph]: start epoch 57.
[2023-03-21 20:05:49] PRINT [03/21 20:05:49 graph]: # Epoch 57: train_loss: 0.4299 | lr: 0.000322
[2023-03-21 20:05:49] PRINT [03/21 20:05:49 graph]: start epoch 58.
[2023-03-21 20:05:49] PRINT [03/21 20:05:49 graph]: # Epoch 58: train_loss: 0.4287 | lr: 0.000322
[2023-03-21 20:05:49] PRINT [03/21 20:05:49 graph]: start epoch 59.
[2023-03-21 20:05:49] PRINT [03/21 20:05:49 graph]: # Epoch 59: train_loss: 0.4278 | lr: 0.000322
[2023-03-21 20:05:49] PRINT [03/21 20:05:49 graph]: start epoch 60.
[2023-03-21 20:05:49] PRINT [03/21 20:05:49 graph]: # Epoch 60: train_loss: 0.4267 | lr: 0.000322
[2023-03-21 20:05:49] PRINT [03/21 20:05:49 graph]: start epoch 61.
[2023-03-21 20:05:49] PRINT [03/21 20:05:49 graph]: # Epoch 61: train_loss: 0.4258 | lr: 0.000322
[2023-03-21 20:05:49] PRINT [03/21 20:05:49 graph]: start epoch 62.
[2023-03-21 20:05:50] PRINT [03/21 20:05:50 graph]: # Epoch 62: train_loss: 0.4254 | lr: 0.000322
[2023-03-21 20:05:50] PRINT [03/21 20:05:50 graph]: start epoch 63.
[2023-03-21 20:05:50] PRINT [03/21 20:05:50 graph]: # Epoch 63: train_loss: 0.4240 | lr: 0.000322
[2023-03-21 20:05:50] PRINT [03/21 20:05:50 graph]: start epoch 64.
[2023-03-21 20:05:50] PRINT [03/21 20:05:50 graph]: # Epoch 64: train_loss: 0.4237 | lr: 0.000322
[2023-03-21 20:05:50] PRINT [03/21 20:05:50 graph]: start epoch 65.
[2023-03-21 20:05:50] PRINT [03/21 20:05:50 graph]: # Epoch 65: train_loss: 0.4222 | lr: 0.000322
[2023-03-21 20:05:50] PRINT [03/21 20:05:50 graph]: start epoch 66.
[2023-03-21 20:05:50] PRINT [03/21 20:05:50 graph]: # Epoch 66: train_loss: 0.4216 | lr: 0.000322
[2023-03-21 20:05:50] PRINT [03/21 20:05:50 graph]: start epoch 67.
[2023-03-21 20:05:51] PRINT [03/21 20:05:51 graph]: # Epoch 67: train_loss: 0.4205 | lr: 0.000322
[2023-03-21 20:05:51] PRINT [03/21 20:05:51 graph]: start epoch 68.
[2023-03-21 20:05:51] PRINT [03/21 20:05:51 graph]: # Epoch 68: train_loss: 0.4201 | lr: 0.000322
[2023-03-21 20:05:51] PRINT [03/21 20:05:51 graph]: start epoch 69.
[2023-03-21 20:05:51] PRINT [03/21 20:05:51 graph]: # Epoch 69: train_loss: 0.4190 | lr: 0.000322
[2023-03-21 20:05:51] PRINT [03/21 20:05:51 graph]: start epoch 70.
[2023-03-21 20:05:51] PRINT [03/21 20:05:51 graph]: # Epoch 70: train_loss: 0.4184 | lr: 0.000322
[2023-03-21 20:05:51] PRINT [03/21 20:05:51 graph]: start epoch 71.
[2023-03-21 20:05:52] PRINT [03/21 20:05:52 graph]: # Epoch 71: train_loss: 0.4178 | lr: 0.000322
[2023-03-21 20:05:52] PRINT [03/21 20:05:52 graph]: start epoch 72.
[2023-03-21 20:05:52] PRINT [03/21 20:05:52 graph]: # Epoch 72: train_loss: 0.4169 | lr: 0.000322
[2023-03-21 20:05:52] PRINT [03/21 20:05:52 graph]: start epoch 73.
[2023-03-21 20:05:52] PRINT [03/21 20:05:52 graph]: # Epoch 73: train_loss: 0.4162 | lr: 0.000322
[2023-03-21 20:05:52] PRINT [03/21 20:05:52 graph]: start epoch 74.
[2023-03-21 20:05:52] PRINT [03/21 20:05:52 graph]: # Epoch 74: train_loss: 0.4155 | lr: 0.000322
[2023-03-21 20:05:52] PRINT [03/21 20:05:52 graph]: start epoch 75.
[2023-03-21 20:05:52] PRINT [03/21 20:05:52 graph]: # Epoch 75: train_loss: 0.4153 | lr: 0.000322
[2023-03-21 20:05:52] PRINT [03/21 20:05:52 graph]: start epoch 76.
[2023-03-21 20:05:53] PRINT [03/21 20:05:53 graph]: # Epoch 76: train_loss: 0.4167 | lr: 0.000322
[2023-03-21 20:05:53] PRINT [03/21 20:05:53 graph]: start epoch 77.
[2023-03-21 20:05:53] PRINT [03/21 20:05:53 graph]: # Epoch 77: train_loss: 0.4170 | lr: 0.000322
[2023-03-21 20:05:53] PRINT [03/21 20:05:53 graph]: start epoch 78.
[2023-03-21 20:05:53] PRINT [03/21 20:05:53 graph]: # Epoch 78: train_loss: 0.4157 | lr: 0.000322
[2023-03-21 20:05:53] PRINT [03/21 20:05:53 graph]: start epoch 79.
[2023-03-21 20:05:53] PRINT [03/21 20:05:53 graph]: # Epoch 79: train_loss: 0.4134 | lr: 0.000322
[2023-03-21 20:05:53] PRINT [03/21 20:05:53 graph]: start epoch 80.
[2023-03-21 20:05:53] PRINT [03/21 20:05:53 graph]: # Epoch 80: train_loss: 0.4140 | lr: 0.000322
[2023-03-21 20:05:53] PRINT [03/21 20:05:53 graph]: start epoch 81.
[2023-03-21 20:05:54] PRINT [03/21 20:05:54 graph]: # Epoch 81: train_loss: 0.4112 | lr: 0.000322
[2023-03-21 20:05:54] PRINT [03/21 20:05:54 graph]: start epoch 82.
[2023-03-21 20:05:54] PRINT [03/21 20:05:54 graph]: # Epoch 82: train_loss: 0.4124 | lr: 0.000322
[2023-03-21 20:05:54] PRINT [03/21 20:05:54 graph]: start epoch 83.
[2023-03-21 20:05:54] PRINT [03/21 20:05:54 graph]: # Epoch 83: train_loss: 0.4099 | lr: 0.000322
[2023-03-21 20:05:54] PRINT [03/21 20:05:54 graph]: start epoch 84.
[2023-03-21 20:05:54] PRINT [03/21 20:05:54 graph]: # Epoch 84: train_loss: 0.4102 | lr: 0.000322
[2023-03-21 20:05:54] PRINT [03/21 20:05:54 graph]: start epoch 85.
[2023-03-21 20:05:54] PRINT [03/21 20:05:54 graph]: # Epoch 85: train_loss: 0.4087 | lr: 0.000322
[2023-03-21 20:05:54] PRINT [03/21 20:05:54 graph]: start epoch 86.
[2023-03-21 20:05:55] PRINT [03/21 20:05:55 graph]: # Epoch 86: train_loss: 0.4078 | lr: 0.000322
[2023-03-21 20:05:55] PRINT [03/21 20:05:55 graph]: start epoch 87.
[2023-03-21 20:05:55] PRINT [03/21 20:05:55 graph]: # Epoch 87: train_loss: 0.4076 | lr: 0.000322
[2023-03-21 20:05:55] PRINT [03/21 20:05:55 graph]: start epoch 88.
[2023-03-21 20:05:55] PRINT [03/21 20:05:55 graph]: # Epoch 88: train_loss: 0.4060 | lr: 0.000322
[2023-03-21 20:05:55] PRINT [03/21 20:05:55 graph]: start epoch 89.
[2023-03-21 20:05:55] PRINT [03/21 20:05:55 graph]: # Epoch 89: train_loss: 0.4060 | lr: 0.000322
[2023-03-21 20:05:55] PRINT [03/21 20:05:55 graph]: start epoch 90.
[2023-03-21 20:05:56] PRINT [03/21 20:05:56 graph]: # Epoch 90: train_loss: 0.4049 | lr: 0.000322
[2023-03-21 20:05:56] PRINT [03/21 20:05:56 graph]: start epoch 91.
[2023-03-21 20:05:56] PRINT [03/21 20:05:56 graph]: # Epoch 91: train_loss: 0.4045 | lr: 0.000322
[2023-03-21 20:05:56] PRINT [03/21 20:05:56 graph]: start epoch 92.
[2023-03-21 20:05:56] PRINT [03/21 20:05:56 graph]: # Epoch 92: train_loss: 0.4034 | lr: 0.000322
[2023-03-21 20:05:56] PRINT [03/21 20:05:56 graph]: start epoch 93.
[2023-03-21 20:05:56] PRINT [03/21 20:05:56 graph]: # Epoch 93: train_loss: 0.4033 | lr: 0.000322
[2023-03-21 20:05:56] PRINT [03/21 20:05:56 graph]: start epoch 94.
[2023-03-21 20:05:56] PRINT [03/21 20:05:56 graph]: # Epoch 94: train_loss: 0.4023 | lr: 0.000322
[2023-03-21 20:05:56] PRINT [03/21 20:05:56 graph]: start epoch 95.
[2023-03-21 20:05:57] PRINT [03/21 20:05:57 graph]: # Epoch 95: train_loss: 0.4017 | lr: 0.000322
[2023-03-21 20:05:57] PRINT [03/21 20:05:57 graph]: start epoch 96.
[2023-03-21 20:05:57] PRINT [03/21 20:05:57 graph]: # Epoch 96: train_loss: 0.4012 | lr: 0.000322
[2023-03-21 20:05:57] PRINT [03/21 20:05:57 graph]: start epoch 97.
[2023-03-21 20:05:57] PRINT [03/21 20:05:57 graph]: # Epoch 97: train_loss: 0.4002 | lr: 0.000322
[2023-03-21 20:05:57] PRINT [03/21 20:05:57 graph]: start epoch 98.
[2023-03-21 20:05:57] PRINT [03/21 20:05:57 graph]: # Epoch 98: train_loss: 0.4001 | lr: 0.000322
[2023-03-21 20:05:57] PRINT [03/21 20:05:57 graph]: start epoch 99.
[2023-03-21 20:05:57] PRINT [03/21 20:05:57 graph]: # Epoch 99: train_loss: 0.4001 | lr: 0.000322
[2023-03-21 20:05:57] PRINT [03/21 20:05:57 graph]: start epoch 100.
[2023-03-21 20:05:58] PRINT [03/21 20:05:58 graph]: # Epoch 100: train_loss: 0.3991 | lr: 0.000322
[2023-03-21 20:05:58] PRINT [03/21 20:05:58 graph]: start epoch 101.
[2023-03-21 20:05:58] PRINT [03/21 20:05:58 graph]: # Epoch 101: train_loss: 0.3985 | lr: 0.000322
